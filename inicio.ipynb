{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b839a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLOQUE 1: Importaciones y configuraci√≥n inicial\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from urllib.parse import urljoin, quote\n",
    "import json\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(\"üï∑Ô∏è Comenzando la infiltraci√≥n en Books To Scrape...\")\n",
    "\n",
    "\n",
    "# BLOQUE 2: Funciones de Web Scraping \n",
    "\n",
    "def get_all_categories ():\n",
    "    ''' OBTIENE TODAS LAS CATEGORIAS DEL SITIO'''\n",
    "    url = \"https://books.toscrape.com\"\n",
    "    respuesta = requests.get(url) # se descarga la web \n",
    "    soup = BeautifulSoup(respuesta.content, 'html.parser')  \n",
    "    # convierte texto HTML ilegible, en un objeto inteligente que se pueda navegar \n",
    "    \n",
    "    categories = []\n",
    "    nav_list = soup.find('ul', class_='nav nav-list')\n",
    "    if nav_list:\n",
    "        category_links = nav_list.find_all ('a'[1:]) # Saltar \"Books\"\n",
    "        for link in category_links:\n",
    "            category_name = link.text.strip()\n",
    "            category_url = urljoin(url, link['href'])\n",
    "            categories.append({\n",
    "                'name' : category_name,\n",
    "                'url' : category_url\n",
    "            })\n",
    "            \n",
    "    print (f\"üéØ Encontradas {len(categories)} categorias\")\n",
    "    return categories \n",
    "\n",
    "\n",
    "def book_quantity (book_url): \n",
    "    ''' OBTIENE LA CANTIDAD EN STOCK DE UN LIBRO DESDE SU PAGINA DE DETALLES  '''\n",
    "    try:\n",
    "        soup_quantity = BeautifulSoup(requests.get(book_url).content,'html.parser') \n",
    "        quantity_text = soup_quantity.select_one('p.instock.availability').get_text(strip=True)\n",
    "        match = re.search(r'\\((\\d+))', quantity_text)\n",
    "        if match:\n",
    "            return int (match.group(1)) # devuelve la cantidad encontrada \n",
    "        else:\n",
    "            return 0 # si no se encuentra la cantidad, devuelve 0 \n",
    "    except Exception as e :\n",
    "        print (f\"‚ùå Erorr obteniendo cantidad para {book_url}:{e}\")\n",
    "        return 0 # en caso de error, devuelve 0 \n",
    "    \n",
    "\n",
    "\n",
    "def scrape_books_from_page(page_url): \n",
    "    ''' SCRAPE LIBROS DE UNA PAGINA ESPECIFICA  '''\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.content,'html.parser' )\n",
    "    \n",
    "    books = []\n",
    "    book_containers = soup.find_all ('article', class_ ='product_pod')\n",
    "    \n",
    "    for book in book_containers: \n",
    "        try:\n",
    "            # TITULO\n",
    "            title_element = book.find('h3').find('a')\n",
    "            title = title_element['title']\n",
    "\n",
    "            # URL DEL LIBRO PARA MAS DETALLES \n",
    "            book_url = urljoin(page_url, title_element['href'])\n",
    "            \n",
    "            price_element = book.find('p', class_= 'price_color')\n",
    "            price_text = price_element.text.strip() if price_element else \"¬£0.00\"\n",
    "            price = float (price_text.lstrip('√Ç¬£'))\n",
    "            \n",
    "            # RATING \n",
    "            rating_element = book.find ('p', class_= 'star-rating')\n",
    "            rating_class = rating_element['class'][1] if rating_element else 'Zero'\n",
    "            rating_map = {'One': 1, 'Two' : 2 , 'Three': 3, 'Four': 4, 'Five': 5, \"Zero\" : 0 } \n",
    "            rating = rating_map.get(rating_class, 0)\n",
    "            \n",
    "            \n",
    "            # STOCK \n",
    "            stock_element = book.find ('p', class_= 'instock availability')\n",
    "            in_stock = 'In stock' in stock_element.text if stock_element else False \n",
    "            quantity = book_quantity(book_url)\n",
    "            \n",
    "            \n",
    "            books.append({\n",
    "                \n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'rating' : rating,\n",
    "                'in_stock' : in_stock,\n",
    "                'quantity': quantity,\n",
    "                'url': book_url\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error procesando libro: {e}\") \n",
    "            continue\n",
    "    return books \n",
    "\n",
    "def scrape_all_books (): \n",
    "    ''' SCRAPE TODOS LOS LIBROS DEL SITIO '''\n",
    "    all_books = []\n",
    "    categories = get_all_categories()\n",
    "    for i, category in enumerate(categories):\n",
    "        print (f\"Procesando categoria {i+1}/ {len(categories)}: {category['name']}\")\n",
    "        \n",
    "        page_num = 1 \n",
    "        current_url = category['url']\n",
    "        \n",
    "        while current_url: \n",
    "            print (f\" Pagina {page_num}\")\n",
    "            books_on_page = scrape_books_from_page(current_url)\n",
    "            \n",
    "            for book in books_on_page:\n",
    "                book['category'] = category['name']\n",
    "                \n",
    "            all_books.extend(books_on_page)\n",
    "            \n",
    "            # BUSCAR SIGUIENTE PAGINA \n",
    "            response = requests.get(current_url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            next_button = soup.find('li', class_= 'next')\n",
    "            \n",
    "            if next_button and next_button.find('a'):\n",
    "                next_url = next_button.find('a')['href']\n",
    "                current_url = urljoin(current_url, next_url)\n",
    "                page_num += 1 \n",
    "            else:\n",
    "                current_url = None \n",
    "                \n",
    "            time.sleep (0.5) # ser amigables con el servidor \n",
    "        \n",
    "    print (f\" üéâ Scraping completado: {len(all_books)} libros encontrados\")\n",
    "    return all_books\n",
    "\n",
    "\n",
    "# BLOQUE 3: EJECUTAR EL SCRAPING \n",
    "books_data = scrape_all_books\n",
    "\n",
    "# Mostrar muestra de datos \n",
    "print (\"\\n Muestra de los primeros 3 libros: \")\n",
    "for i, book in enumerate(books_data[:3]):\n",
    "    print(f\"{i+1}. {book['title']} - {book['price']} - ‚≠ê{book['rating']} - {book['category']} - {book['quantity']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e46a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de base de datos ( DDL) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
