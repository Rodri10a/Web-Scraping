# ğŸ“š Books Detective - Web Scraping Challenge

> *Proyecto de web scraping y anÃ¡lisis de datos de Books to Scrape con integraciÃ³n a Google Books API*

## ğŸ¯ DescripciÃ³n del Proyecto

Books Detective es un proyecto integral de web scraping que extrae informaciÃ³n de **1000 libros** de 50 categorÃ­as diferentes desde [Books to Scrape](https://books.toscrape.com/), enriquece los datos con la API de Google Books, y almacena toda la informaciÃ³n en una base de datos relacional SQLite para realizar anÃ¡lisis avanzados mediante consultas SQL.

## âœ¨ CaracterÃ­sticas Principales

- ğŸ•·ï¸ **Web Scraping Completo**: ExtracciÃ³n automatizada de 1000 libros en 50 categorÃ­as
- ğŸ” **Enriquecimiento de Datos**: IntegraciÃ³n con Google Books API para obtener informaciÃ³n detallada de autores
- ğŸ’¾ **Base de Datos Relacional**: DiseÃ±o normalizado con relaciones muchos-a-muchos
- ğŸ“Š **AnÃ¡lisis SQL Avanzado**: Consultas con window functions y subconsultas complejas
- âš¡ **OptimizaciÃ³n**: ImplementaciÃ³n de Ã­ndices y anÃ¡lisis de rendimiento
- ğŸ“ˆ **ExportaciÃ³n CSV**: Datos completos exportados para anÃ¡lisis adicionales

## ğŸ› ï¸ TecnologÃ­as Utilizadas

```python
- Python 3.12
- BeautifulSoup4 - Web scraping y parseo HTML
- Requests - Peticiones HTTP
- SQLite3 - Base de datos relacional
- Pandas - ManipulaciÃ³n y anÃ¡lisis de datos
- Google Books API - Enriquecimiento de datos
- ThreadPoolExecutor - Procesamiento paralelo
```

## ğŸ“‹ Requisitos

Las dependencias del proyecto estÃ¡n listadas en `requirements.txt`:

```
beautifulsoup4==4.14.3
requests==2.32.5
pandas==3.0.0
numpy==2.4.1
```

## ğŸš€ InstalaciÃ³n y Uso

### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/books-detective.git
cd books-detective
```

### 2. Crear entorno virtual (recomendado)
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Ejecutar el proyecto
```bash
jupyter notebook inicio.ipynb
```

## ğŸ“Š Estructura de la Base de Datos

El proyecto utiliza un modelo relacional normalizado con las siguientes tablas:

### Tablas Principales

**ğŸ“– Libros**
- `id` (PRIMARY KEY)
- `titulo`
- `precio`
- `rating` (1-5 estrellas)
- `en_stock`
- `categoria_id` (FOREIGN KEY)
- `descripcion`

**âœï¸ Autores**
- `id` (PRIMARY KEY)
- `nombre`

**ğŸ“‚ CategorÃ­as**
- `id` (PRIMARY KEY)
- `nombre`

**ğŸ”— Libros_Autores** (Tabla de relaciÃ³n)
- `libro_id` (FOREIGN KEY)
- `autor_id` (FOREIGN KEY)

## ğŸ” Funcionalidades del Proyecto

### Web Scraping
- ExtracciÃ³n automÃ¡tica de 50 categorÃ­as
- NavegaciÃ³n paginada por categorÃ­a
- ExtracciÃ³n de datos: tÃ­tulo, precio, rating, stock, descripciÃ³n
- Manejo de errores y reintentos

### IntegraciÃ³n API
- Consultas a Google Books API
- BÃºsqueda de autores por tÃ­tulo
- Manejo de respuestas y fallbacks
- Procesamiento paralelo con ThreadPoolExecutor

### AnÃ¡lisis de Datos
El proyecto incluye 5 consultas SQL avanzadas:

1. **Top 10 Autores ProlÃ­ficos**: Autores con mÃ¡s libros usando window functions
2. **Libros Caros por CategorÃ­a**: Precios comparados con promedio de categorÃ­a
3. **Autores VersÃ¡tiles**: Autores que escriben en mÃºltiples gÃ©neros
4. **AnÃ¡lisis de Precios**: DistribuciÃ³n de precios con percentiles
5. **Mejores Libros EconÃ³micos**: Libros de alta calificaciÃ³n a bajo precio

### OptimizaciÃ³n
- ImplementaciÃ³n de Ã­ndices en columnas clave
- AnÃ¡lisis antes/despuÃ©s de indexaciÃ³n
- MediciÃ³n de tiempos de ejecuciÃ³n
- Mejora documentada del rendimiento

## ğŸ“ Archivos del Proyecto

```
books-detective/
â”‚
â”œâ”€â”€ inicio.ipynb                           # Notebook principal con todo el cÃ³digo
â”œâ”€â”€ requirements.txt                       # Dependencias del proyecto
â”œâ”€â”€ books_detective.db                     # Base de datos SQLite generada
â”œâ”€â”€ books_detective_complete_data.csv      # Datos exportados en CSV
â”œâ”€â”€ README.md                              # Este archivo
â””â”€â”€ .gitignore                             # Archivos ignorados por Git
```

## ğŸ“ˆ Resultados

El proyecto procesa exitosamente:
- âœ… 1000 libros scrapeados
- âœ… 50 categorÃ­as Ãºnicas
- âœ… 600+ autores identificados
- âœ… Datos enriquecidos con API
- âœ… Base de datos relacional completa
- âœ… Consultas optimizadas con Ã­ndices

## ğŸ“ Aprendizajes

Este proyecto demuestra competencias en:
- Web scraping Ã©tico y responsable
- DiseÃ±o de bases de datos relacionales
- IntegraciÃ³n de APIs externas
- OptimizaciÃ³n de consultas SQL
- Procesamiento paralelo en Python
- AnÃ¡lisis y visualizaciÃ³n de datos

